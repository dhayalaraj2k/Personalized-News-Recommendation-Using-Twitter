{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import codecs\n",
    "import string\n",
    "from happyfuntokenizing import *\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "basepath = \"\"\n",
    "\n",
    "mycompile = lambda pat:  re.compile(pat,  re.UNICODE)\n",
    "\n",
    "OFFSET = 2\n",
    "CONF_THR = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### DICTIONARY FILE PATH ####################\n",
    "\n",
    "SUBJECTIVE_PATH = basepath+'DICTIONARY/subjclueslen1-HLTEMNLP05.tff'\n",
    "COMMUNAL_PATH = basepath+'DICTIONARY/communal_dictionary.txt'\n",
    "RELIGION_PATH = basepath+'DICTIONARY/communal_race.txt'\n",
    "SLANG_PATH = basepath+'DICTIONARY/english_slang.txt'\n",
    "SWEAR_PATH = basepath+'DICTIONARY/english_swear.txt'\n",
    "WH_PATH = basepath+'DICTIONARY/english_whwords.txt'\n",
    "INTENSIFIER_PATH = basepath+'DICTIONARY/english_intensifier.txt'\n",
    "COMMUNAL_HASHTAG_PATH = basepath+'DICTIONARY/communal_hashtag_dictionary.txt'\n",
    "ANTICOMMUNAL_COLLOCATIONS_PATH = basepath+'DICTIONARY/anticommunal_collocations.txt'\n",
    "ANTICOMMUNAL_HASHTAGS_PATH = basepath+'DICTIONARY/anticommunal_hashtags.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedstopwords = stopwords.words(\"english\")\t# English Stop Words\n",
    "Tagger_Path = basepath+'ark-tweet-nlp-0.3.2/'\n",
    "lmtzr = WordNetLemmatizer()\t\t# Lemmatizer\n",
    "\n",
    "SUBJECTIVE = {}\n",
    "COMMUNAL = {}\n",
    "RELIGION = {}\n",
    "SLANG = {}\n",
    "HASHTAG = {}\n",
    "WH = {}\n",
    "INTENSIFIER = {}\n",
    "A_COLL = []\n",
    "A_HASH = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads Dictionary files and stores them in respective dictionary\n",
    "\n",
    "def Read_Files():\n",
    "\n",
    "    fp = open(SUBJECTIVE_PATH,'r')\n",
    "    for l in fp:\n",
    "        wl = l.split()\n",
    "        Type = wl[0].split('=')[1].strip(' \\t\\n\\r')\n",
    "        pos_tag = wl[3].split('=')[1].strip(' \\t\\n\\r')\n",
    "        Tag = wl[5].split('=')[1].strip(' \\t\\n\\r')\n",
    "        word = wl[2].split('=')[1].strip(' \\t\\n\\r')\n",
    "\n",
    "\n",
    "        if Type=='strongsubj':\n",
    "            if SUBJECTIVE.__contains__(word)==False:\n",
    "                if Tag=='negative':\n",
    "                    SUBJECTIVE[word] = -1\n",
    "                elif Tag=='positive':\n",
    "                    SUBJECTIVE[word] = 1\n",
    "                else:\n",
    "                    SUBJECTIVE[word] = 0\n",
    "    fp.close()\n",
    "\n",
    "    fp = open(COMMUNAL_HASHTAG_PATH,'r')\n",
    "    for l in fp:\n",
    "        w = l.strip(' #\\t\\n\\r').lower()\n",
    "        if HASHTAG.__contains__(w)==False:\n",
    "            HASHTAG[w] = 1\n",
    "    fp.close()\n",
    "    \n",
    "    fp = open(WH_PATH,'r')\n",
    "    for l in fp:\n",
    "        w = l.strip(' #\\t\\n\\r').lower()\n",
    "        if WH.__contains__(w)==False:\n",
    "            WH[w] = 1\n",
    "    fp.close()\n",
    "    \n",
    "    fp = open(INTENSIFIER_PATH,'r')\n",
    "    for l in fp:\n",
    "        w = l.strip(' \\t\\n\\r').lower()\n",
    "        if INTENSIFIER.__contains__(w)==False:\n",
    "            INTENSIFIER[w] = 1\n",
    "    fp.close()\n",
    "\n",
    "    fp = open(RELIGION_PATH,'r')\n",
    "    for l in fp:\n",
    "        w = l.strip(' \\t\\n\\r').lower()\n",
    "        if RELIGION.__contains__(w)==False:\n",
    "            RELIGION[w] = 1\n",
    "    fp.close()\n",
    "    \n",
    "    fp = open(COMMUNAL_PATH,'r')\n",
    "    for l in fp:\n",
    "        wl = l.split('\\t')\n",
    "        w = wl[0].strip(' \\t\\n\\r').lower()\n",
    "        if COMMUNAL.__contains__(w)==False:\n",
    "            x1 = wl[1].strip(' \\t\\n\\r')\n",
    "            x2 = wl[2].strip(' \\t\\n\\r')\n",
    "            x3 = wl[3].strip(' \\t\\n\\r')\n",
    "            if len(x2)==0:\n",
    "                COMMUNAL[w] = (int(wl[1]),0)\n",
    "            else:\n",
    "                COMMUNAL[w] = (int(wl[1]),int(wl[2]))\n",
    "    fp.close()\n",
    "    \n",
    "\n",
    "    fp = open(SLANG_PATH,'r')\n",
    "    for l in fp:\n",
    "        w = l.strip(' \\t\\n\\r').lower()\n",
    "        if SLANG.__contains__(w)==False:\n",
    "            SLANG[w] = 1\n",
    "    fp.close()\n",
    "\n",
    "    fp = open(SWEAR_PATH,'r')\n",
    "    for l in fp:\n",
    "        w = l.strip(' \\t\\n\\r').lower()\n",
    "        if SLANG.__contains__(w)==False:\n",
    "            SLANG[w] = 1\n",
    "    fp.close()\n",
    "\n",
    "    fp = open(ANTICOMMUNAL_COLLOCATIONS_PATH,'r')\n",
    "    for l in fp:\n",
    "        w = l.strip(' \\t\\n\\r').lower()\n",
    "        A_COLL.append(w)\n",
    "        # print(w)\n",
    "    fp.close()\n",
    "\n",
    "    fp = open(ANTICOMMUNAL_HASHTAGS_PATH,'r')\n",
    "    for l in fp:\n",
    "        w = l.strip(' \\t\\n\\r').lower()\n",
    "        A_HASH.append(w)\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if a unigram is strongsub and negative\n",
    "\n",
    "def getnegativesubjective(unigram):\n",
    "    for x in unigram:\n",
    "        if SUBJECTIVE.__contains__(x)==True:\n",
    "            if SUBJECTIVE[x]==-1:\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def getcollocationterm(unigram,bigram,trigram):\n",
    "    flag = 0\n",
    "    for u in unigram:\n",
    "        if A_COLL.__contains__(u)==True:\n",
    "            flag = 1\n",
    "            break\n",
    "    if flag==1:\n",
    "        return 1\n",
    "\n",
    "    for u in bigram:\n",
    "        if A_COLL.__contains__(u)==True:\n",
    "            flag = 1\n",
    "            break\n",
    "    if flag==1:\n",
    "        return 1\n",
    "\n",
    "    for u in trigram:\n",
    "        if A_COLL.__contains__(u)==True:\n",
    "            flag = 1\n",
    "            break\n",
    "    if flag==1:\n",
    "        return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "def getreligiouscount(unigram):\n",
    "    flag = 0\n",
    "    temp = set([])\n",
    "    for u in unigram:\n",
    "        if RELIGION.__contains__(u)==True:\n",
    "            temp.add(u)\n",
    "            #flag+=1\n",
    "    if len(temp)>2:\n",
    "        return 1\n",
    "    #if flag>2:\n",
    "    #        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if unigram, bigram and trigram are communal slang or not\n",
    "\n",
    "def getcommunalslang(unigram,bigram,trigram):\n",
    "    flag = 0\n",
    "    for u in unigram:\n",
    "        if COMMUNAL.__contains__(u)==True:\n",
    "            v = COMMUNAL[u]\n",
    "            if v[1]==1:\n",
    "                flag=1\n",
    "                break\n",
    "    if flag==1:\n",
    "        return 1\n",
    "    for u in bigram:\n",
    "        if COMMUNAL.__contains__(u)==True:\n",
    "            v = COMMUNAL[u]\n",
    "            if v[1]==1:\n",
    "                flag=1\n",
    "                break\n",
    "    if flag==1:\n",
    "        return 1\n",
    "    for u in trigram:\n",
    "        if COMMUNAL.__contains__(u)==True:\n",
    "            v = COMMUNAL[u]\n",
    "            if v[1]==1:\n",
    "                flag=1\n",
    "                break\n",
    "    if flag==1:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def get_religious_sarcasm(unigram):\n",
    "        flag_REL = 0\n",
    "        for u in unigram:\n",
    "                if RELIGION.__contains__(u)==True:\n",
    "                        flag_REL = 1\n",
    "                        break\n",
    "\n",
    "        flag_INT = 0\n",
    "        for u in unigram:\n",
    "                if INTENSIFIER.__contains__(u)==True:\n",
    "                        flag_INT = 1\n",
    "                        break\n",
    "\n",
    "        flag_WH = 0\n",
    "        for u in unigram:\n",
    "                if WH.__contains__(u)==True:\n",
    "                        flag_WH = 1\n",
    "                        break\n",
    "\n",
    "        if flag_REL==1 and flag_WH==1:\n",
    "                return 1\n",
    "        if flag_REL==1 and flag_INT==1:\n",
    "                return 1\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is a communal or religious term and a slang or subjective negative term in a window of +-3 \n",
    "\n",
    "def get_religious_slang(unigram,bigram,trigram):\n",
    "\n",
    "    ################################# First Check Unigrams ################################################################\n",
    "    flag = 0\n",
    "    for i in range(0,len(list(unigram)),1):\n",
    "        w = unigram[i]\n",
    "        if COMMUNAL.__contains__(w)==True or RELIGION.__contains__(w)==True:\n",
    "            L = i - OFFSET\n",
    "            R = i + OFFSET\n",
    "            if L<0:\n",
    "                L = 0\n",
    "            if R >= len(list(unigram)):\n",
    "                R = len(list(unigram)) - 1\n",
    "            for j in range(L,i,1):\n",
    "                if SUBJECTIVE.__contains__(unigram[j])==True:\n",
    "                    if SUBJECTIVE[unigram[j]]==-1:\n",
    "                        flag=1\n",
    "                        break\n",
    "                elif SLANG.__contains__(unigram[j])==True:\n",
    "                    flag=1\n",
    "                    break\n",
    "            if flag==1:\n",
    "                return 1\n",
    "            for j in range(i+1,R+1,1):\n",
    "                if SUBJECTIVE.__contains__(unigram[j])==True:\n",
    "                    if SUBJECTIVE[unigram[j]]==-1:\n",
    "                        flag=1\n",
    "                        break\n",
    "                elif SLANG.__contains__(unigram[j])==True:\n",
    "                    flag=1\n",
    "                    break\n",
    "            if flag==1:\n",
    "                return 1\n",
    "\n",
    "    ################################# Second Check Bigrams ################################################################\n",
    "\n",
    "    flag = 0\n",
    "    for i in range(0,len(list(bigram)),1):\n",
    "        w = bigram[i]\n",
    "        if COMMUNAL.__contains__(w)==True or RELIGION.__contains__(w)==True:\n",
    "            L = i - OFFSET\n",
    "            R = i + OFFSET\n",
    "            if L<0:\n",
    "                L = 0\n",
    "            if R >= len(list(bigram)):\n",
    "                R = len(list(bigram)) - 1\n",
    "\n",
    "            str_before = bigram[L]\n",
    "\n",
    "            for j in range(L+1,i-1,1):\n",
    "                str_before = str_before+' '+(bigram[j].split(' '))[1]\n",
    "\n",
    "            unigram_before = str_before.split(' ')\n",
    "\n",
    "            trigram_before = []\n",
    "\n",
    "            if len(list(unigram_before))>=3:\n",
    "                for j in range(0,len(list(unigram_before))-2,1):\n",
    "                    s = unigram_before[j] + ' ' + unigram_before[j+1] + ' ' + unigram_before[j+2]\n",
    "                    trigram_before.append(s)\n",
    "\n",
    "            for j in range(L,i,1):\n",
    "                if SUBJECTIVE.__contains__(bigram[j])==True:\n",
    "                    if SUBJECTIVE[bigram[j]]==-1:\n",
    "                        flag=1\n",
    "                        break\n",
    "                elif SLANG.__contains__(bigram[j])==True:\n",
    "                    flag=1\n",
    "                    break\n",
    "            if flag==1:\n",
    "                return 1\n",
    "\n",
    "            for j in range(0,len(list(unigram_before)),1):\n",
    "                if SUBJECTIVE.__contains__(unigram_before[j])==True:\n",
    "                    if SUBJECTIVE[unigram_before[j]]==-1:\n",
    "                        flag=1\n",
    "                        break\n",
    "                elif SLANG.__contains__(unigram_before[j])==True:\n",
    "                    flag=1\n",
    "                    break\n",
    "            if flag==1:\n",
    "                return 1\n",
    "\n",
    "\n",
    "\n",
    "            for j in range(0,len(list(trigram_before)),1):\n",
    "                if SUBJECTIVE.__contains__(trigram_before[j])==True:\n",
    "                    if SUBJECTIVE[trigram_before[j]]==-1:\n",
    "                        flag=1\n",
    "                        break\n",
    "                elif SLANG.__contains__(trigram_before[j])==True:\n",
    "                    flag=1\n",
    "                    break\n",
    "            if flag==1:\n",
    "                return 1\n",
    "\n",
    "\n",
    "            str_after = ''\n",
    "\n",
    "\n",
    "            for j in range(i+1,R+1,1):\n",
    "                str_after = str_after+' '+(bigram[j].split(' '))[1]\n",
    "\n",
    "            unigram_after = str_after.split(' ')\n",
    "\n",
    "            trigram_after = []\n",
    "\n",
    "            if len(unigram_after)>=3:\n",
    "                for j in range(0,len(list(unigram_after))-2,1):\n",
    "                    s = unigram_after[j] + ' ' + unigram_after[j+1] + ' ' + unigram_after[j+2]\n",
    "                    trigram_after.append(s)\n",
    "\n",
    "\n",
    "            for j in range(i+1,R+1,1):\n",
    "                if SUBJECTIVE.__contains__(bigram[j])==True:\n",
    "                    if SUBJECTIVE[bigram[j]]==-1:\n",
    "                        flag=1\n",
    "                        break\n",
    "                elif SLANG.__contains__(bigram[j])==True:\n",
    "                    flag=1\n",
    "                    break\n",
    "            if flag==1:\n",
    "                return 1\n",
    "\n",
    "\n",
    "            for j in range(0,len(list(unigram_after)),1):\n",
    "                if SUBJECTIVE.__contains__(unigram_after[j])==True:\n",
    "                    if SUBJECTIVE[unigram_after[j]]==-1:\n",
    "                        flag=1\n",
    "                        break\n",
    "                elif SLANG.__contains__(unigram_after[j])==True:\n",
    "                    flag=1\n",
    "                    break\n",
    "            if flag==1:\n",
    "                return 1\n",
    "\n",
    "\n",
    "            # print(str_before, unigram_before, str_after, unigram_after)\n",
    "\n",
    "            for j in range(0,len(list(trigram_after)),1):\n",
    "                if SUBJECTIVE.__contains__(trigram_after[j])==True:\n",
    "                    if SUBJECTIVE[trigram_after[j]]==-1:\n",
    "                        flag=1\n",
    "                        break\n",
    "                elif SLANG.__contains__(trigram_after[j])==True:\n",
    "                    flag=1\n",
    "                    break\n",
    "            if flag==1:\n",
    "                return 1\n",
    "\n",
    "    ################################# Third Check Trigrams ################################################################\n",
    "\n",
    "    flag = 0\n",
    "    for i in range(0,len(list(trigram)),1):\n",
    "        w = trigram[i]\n",
    "        # print(w)\n",
    "        if COMMUNAL.__contains__(w)==True or RELIGION.__contains__(w)==True:\n",
    "            L = i - OFFSET\n",
    "            R = i + OFFSET\n",
    "\n",
    "            unigram_before = []\n",
    "\n",
    "            bigram_before = []\n",
    "\n",
    "            if i>=3:\n",
    "                str_before = trigram[i-3]\n",
    "\n",
    "                unigram_before = str_before.split(' ')\n",
    "\n",
    "                if len(list(unigram_before))>=3:\n",
    "                    for j in range(0,len(list(unigram_before))-1,1):\n",
    "                        s = unigram_before[j] + ' ' + unigram_before[j+1]\n",
    "                        bigram_before.append(s)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if L<0:\n",
    "                L = 0\n",
    "            if R >= len(list(trigram)):\n",
    "                R = len(list(trigram)) - 1\n",
    "\n",
    "\n",
    "\n",
    "            for j in range(L,i,1):\n",
    "                if SUBJECTIVE.__contains__(trigram[j])==True:\n",
    "                    if SUBJECTIVE[trigram[j]]==-1:\n",
    "                        flag=1\n",
    "                        break\n",
    "                elif SLANG.__contains__(trigram[j])==True:\n",
    "                    flag=1\n",
    "                    break\n",
    "            if flag==1:\n",
    "                return 1\n",
    "\n",
    "\n",
    "\n",
    "            for j in range(0,len(list(unigram_before)),1):\n",
    "                if SUBJECTIVE.__contains__(unigram_before[j])==True:\n",
    "                    if SUBJECTIVE[unigram_before[j]]==-1:\n",
    "                        flag=1\n",
    "                        break\n",
    "                elif SLANG.__contains__(unigram_before[j])==True:\n",
    "                    flag=1\n",
    "                    break\n",
    "            if flag==1:\n",
    "                return 1\n",
    "\n",
    "\n",
    "            for j in range(0,len(list(bigram_before)),1):\n",
    "                if SUBJECTIVE.__contains__(bigram_before[j])==True:\n",
    "                    if SUBJECTIVE[bigram_before[j]]==-1:\n",
    "                        flag=1\n",
    "                        break\n",
    "                elif SLANG.__contains__(bigram_before[j])==True:\n",
    "                    flag=1\n",
    "                    break\n",
    "            if flag==1:\n",
    "                return 1\n",
    "\n",
    "\n",
    "            unigram_after = []\n",
    "            bigram_after = []\n",
    "\n",
    "            if i<=len(list(trigram))-4:\n",
    "                str_after = trigram[i+3]\n",
    "\n",
    "                unigram_after = str_after.split(' ')\n",
    "\n",
    "                if len(list(unigram_after))>=3:\n",
    "                    for j in range(0,len(unigram_after)-1,1):\n",
    "                        s = unigram_after[j] + ' ' + unigram_after[j+1]\n",
    "                        bigram_after.append(s)\n",
    "\n",
    "\n",
    "            for j in range(i+1,R+1,1):\n",
    "                if SUBJECTIVE.__contains__(trigram[j])==True:\n",
    "                    if SUBJECTIVE[trigram[j]]==-1:\n",
    "                        flag=1\n",
    "                        break\n",
    "                elif SLANG.__contains__(trigram[j])==True:\n",
    "                    flag=1\n",
    "                    break\n",
    "            if flag==1:\n",
    "                return 1\n",
    "\n",
    "\n",
    "            for j in range(0,len(list(unigram_after)),1):\n",
    "                if SUBJECTIVE.__contains__(unigram_after[j])==True:\n",
    "                    if SUBJECTIVE[unigram_after[j]]==-1:\n",
    "                        flag=1\n",
    "                        break\n",
    "                elif SLANG.__contains__(unigram_after[j])==True:\n",
    "                    flag=1\n",
    "                    break\n",
    "            if flag==1:\n",
    "                return 1\n",
    "\n",
    "            for j in range(0,len(list(bigram_after)),1):\n",
    "                if SUBJECTIVE.__contains__(bigram_after[j])==True:\n",
    "                    if SUBJECTIVE[bigram_after[j]]==-1:\n",
    "                        flag=1\n",
    "                        break\n",
    "                elif SLANG.__contains__(bigram_after[j])==True:\n",
    "                    flag=1\n",
    "                    break\n",
    "            if flag==1:\n",
    "                return 1\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return 1 if there is a communal term in unigrm, bigram or trigram\n",
    "\n",
    "def getreligiousterm(unigram,bigram,trigram):\n",
    "    flag = 0\n",
    "    for u in unigram:\n",
    "        if COMMUNAL.__contains__(u)==True:\n",
    "            v = COMMUNAL[u]\n",
    "            if v[0]==1:\n",
    "                flag=1\n",
    "                break\n",
    "    if flag==1:\n",
    "        return 1\n",
    "\n",
    "    for u in bigram:\n",
    "        if COMMUNAL.__contains__(u)==True:\n",
    "            v = COMMUNAL[u]\n",
    "            if v[0]==1:\n",
    "                flag=1\n",
    "                break\n",
    "    if flag==1:\n",
    "        return 1\n",
    "\n",
    "    for u in trigram:\n",
    "        if COMMUNAL.__contains__(u)==True:\n",
    "            v = COMMUNAL[u]\n",
    "            if v[0]==1:\n",
    "                flag=1\n",
    "                break\n",
    "    if flag==1:\n",
    "        return 1\n",
    "\n",
    "    for u in unigram:\n",
    "        if RELIGION.__contains__(u)==True:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return 1 if there is a slang in tweet\n",
    "\n",
    "def getslang(unigram,bigram,trigram):\n",
    "    for u in unigram:\n",
    "        if SLANG.__contains__(u)==True:\n",
    "            return 1\n",
    "\n",
    "    for u in bigram:\n",
    "        if SLANG.__contains__(u)==True:\n",
    "            return 1\n",
    "\n",
    "    for u in trigram:\n",
    "        if SLANG.__contains__(u)==True:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return 1 if there is a communal hashtag in tweet\n",
    "\n",
    "def getcommunalhashtag(unigram):\n",
    "    for u in unigram:\n",
    "        if HASHTAG.__contains__(u)==True:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the input file path:\n",
      "disasterTweets.csv\n",
      "Enter the output file path:\n",
      "output.txt\n"
     ]
    }
   ],
   "source": [
    "######################## LOAD DICTIONARIES ##############################\n",
    "#Read_Files()\n",
    "#########################################################################\n",
    "\n",
    "def multiple_classify(fn,ofname):\n",
    "\n",
    "    Read_Files()\n",
    "    tok = Tokenizer(preserve_case=False)\n",
    "    tagreject = ['U','@','#','~','E','~',',']\n",
    "\n",
    "    fp = open(fn,'r')\n",
    "    fo = open('temp.txt','w')\n",
    "    tweets = []\n",
    "    cnt = 0\n",
    "    for l in fp:\n",
    "        fo.write(l.strip(' \\t\\n\\r').lower() + '\\n')\n",
    "        cnt+=1\n",
    "\n",
    "    fp.close()\n",
    "    fo.close()\n",
    "\n",
    "    command = Tagger_Path + './runTagger.sh --output-format conll temp.txt > tag.txt'\n",
    "    os.system(command)\n",
    "\n",
    "    fp = open('tag.txt','r')\n",
    "    s = ''\n",
    "    h = 0\n",
    "    ah = 0\n",
    "    feature = []\n",
    "    label = []\n",
    "    for l in fp:\n",
    "        wl = l.split('\\t')\n",
    "        if len(wl)>1:\n",
    "            word = wl[0].strip(' #\\t\\n\\r').lower()\n",
    "            tag = wl[1].strip(' \\t\\n\\r')\n",
    "            # print(\"In if\", word, tag)\n",
    "            if tag not in tagreject:\n",
    "                if tag=='N':\n",
    "                    try:\n",
    "                        w = lmtzr.lemmatize(word)\n",
    "                        word = w\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                elif tag=='V':\n",
    "                    try:\n",
    "                        w = Word(word)\n",
    "                        x = w.lemmatize(\"v\")\n",
    "                    except Exception as e:\n",
    "                        x = word\n",
    "                    word = x.lower()\n",
    "                else:\n",
    "                    pass\n",
    "                try:\n",
    "                    s = s + word + ' '\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                    # print(word)\n",
    "                if h==0:\n",
    "                    if HASHTAG.__contains__(word)==True and wl[0].startswith('#')==True:\n",
    "                        h = 1\n",
    "                if ah==0:\n",
    "                    if A_HASH.__contains__(word)==True and wl[0].startswith('#')==True:\n",
    "                        ah = 1\n",
    "            else:\n",
    "                if h==0:\n",
    "                    if HASHTAG.__contains__(word)==True and wl[0].startswith('#')==True:\n",
    "                        h = 1\n",
    "                if ah==0:\n",
    "                    if A_HASH.__contains__(word)==True and wl[0].startswith('#')==True:\n",
    "                        ah = 1\n",
    "        else:\n",
    "            unigram = tok.tokenize(s.strip(' '))\n",
    "            bigram = []\n",
    "            if len(list(unigram))>=2:\n",
    "                for i in range(0,len(list(unigram))-1,1):\n",
    "                    s = unigram[i] + ' ' + unigram[i+1]\n",
    "                    bigram.append(s)\n",
    "            trigram = []\n",
    "            if len(list(unigram))>=3:\n",
    "                for i in range(0,len(list(unigram))-2,1):\n",
    "                    s = unigram[i] + ' ' + unigram[i+1] + ' ' + unigram[i+2]\n",
    "                    trigram.append(s)\n",
    "            NEG_SUBJ = getnegativesubjective(unigram)\n",
    "            REL_TERM = getreligiousterm(unigram,bigram,trigram)\n",
    "            COM_SLNG = getcommunalslang(unigram,bigram,trigram)\n",
    "            SLNG = getslang(unigram,bigram,trigram)\n",
    "            REL_SLNG = get_religious_slang(unigram,bigram,trigram)\n",
    "            REL_SARC = get_religious_sarcasm(unigram)\n",
    "            REL_COUNT = getreligiouscount(unigram)\n",
    "            COL_TERM = getcollocationterm(unigram,bigram,trigram)\n",
    "\n",
    "            if REL_SLNG==1 or COM_SLNG==1 or h==1 or REL_SARC==1:\n",
    "                label.append(1)\n",
    "            elif REL_COUNT==1 or COL_TERM==1 or ah==1:\n",
    "                label.append(3)\n",
    "            else:\n",
    "                label.append(2)\n",
    "            s = ''\n",
    "            h = 0\n",
    "        ah = 0\n",
    "    fp.close()\n",
    "\n",
    "\n",
    "    predicted_label = label\n",
    "\n",
    "    fp = open(fn,'r')\n",
    "    fo = open(ofname,'w')\n",
    "\n",
    "    index = 0\n",
    "    cnt = 0\n",
    "    for l in fp:\n",
    "            try:\n",
    "                s = l.strip() + ','+ str(predicted_label[index])\n",
    "                fo.write(s+'\\n')\n",
    "                index+=1\n",
    "                cnt+=1\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    fp.close()\n",
    "    fo.close()\n",
    "\n",
    "def main():\n",
    "    fn = input(\"Enter the input file path:\\n\")\n",
    "    ofname = input(\"Enter the output file path:\\n\")\n",
    "\n",
    "    multiple_classify(fn, ofname)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
